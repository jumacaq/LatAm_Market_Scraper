# etl/update_data.py
import os
import pandas as pd
from supabase import create_client
from dotenv import load_dotenv

# Import cleaning helpers
from cleaning import clean_jobs#, clean_skills   

load_dotenv()

# ---------------------------------------------------
# SUPABASE CONNECTION
# ---------------------------------------------------
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_KEY")   # Usamos service key SOLO en backend

client = create_client(SUPABASE_URL, SUPABASE_KEY)


# ---------------------------
# ðŸ”¥ HARD DELETE (OpciÃ³n A)
# ---------------------------
def wipe_table(table_name):
    """Delete ALL rows from a table."""
    print(f"âš  Borrando todos los datos de '{table_name}'...")
    client.table(table_name).delete().neq("id", "00000000-0000-0000-0000-000000000000").execute()
    print(f"âœ” Tabla '{table_name}' vaciada correctamente.\n")


# ---------------------------
# ðŸ”½ Descargar datos crudos
# ---------------------------
def load_raw():
    print("ðŸ“¥ Cargando datos desde Supabase...")

    jobs_raw = client.table("jobs").select("*").execute().data
    
    skills_raw = client.table("skills").select("*").execute().data

    print(f"Jobs cargados: {len(jobs_raw)}")
    print(f"Skills cargadas: {len(skills_raw)}")

    df_jobs = pd.DataFrame(jobs_raw)
    df_skills = pd.DataFrame(skills_raw)

    return df_jobs, df_skills


# ---------------------------
# ðŸ”¼ Subir datos limpios
# ---------------------------
def upload_clean_data(df_jobs_clean, df_skills_clean):

    # 1ï¸âƒ£ BORRAR TABLAS COMPLETAS
    wipe_table("skills")     # primero skills (depende de jobs)
    wipe_table("jobs")

    # 2ï¸âƒ£ REINSERTAR JOBS
    print("â¬† Subiendo jobs limpios...")
    if len(df_jobs_clean) > 0:
        client.table("jobs").insert(df_jobs_clean.to_dict(orient="records")).execute()
        print(f"âœ” Insertados {len(df_jobs_clean)} jobs limpios.\n")
    else:
        print("âš  No hay jobs limpios para insertar.\n")

    # 3ï¸âƒ£ REINSERTAR SKILLS
    print("â¬† Subiendo skills limpias...")
    if len(df_skills_clean) > 0:
        client.table("skills").insert(df_skills_clean.to_dict(orient="records")).execute()
        print(f"âœ” Insertadas {len(df_skills_clean)} skills limpias.\n")
    else:
        print("âš  No hay skills limpias para insertar.\n")


# ---------------------------
# ðŸš€ MAIN ETL PROCESS
# ---------------------------
def run_etl():

    # cargar datos del scraping
    #df_jobs, df_skills = load_raw()

    # limpiar jobs
    #print("\nðŸ§¹ Limpiando tabla jobs...")
    #df_jobs_clean = clean_jobs(df_jobs)
    #print(f"Jobs tras limpieza: {len(df_jobs_clean)}")

    # limpiar skills
    #print("\nðŸ§¹ (Saltado) No se aplica limpieza de skills...")
    #df_skills_clean = df_skills.copy()
    #print(f"Skills tras limpieza: {len(df_skills_clean)}")


    # subir
    #upload_clean_data(df_jobs_clean, df_skills_clean)

    #print("\nðŸŽ¯ ETL COMPLETADO CON Ã‰XITO\n")


if __name__ == "__main__":
    run_etl()